{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning - Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification of protein sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proteins are polymers made of 20 different amino acids. Proteins have been classified into different families based on their sequence similarity. \n",
    "Positive and negative datasets corresponding to one of the protein family are available at http://www.imtech.res.in/raghava/icaars/supplementary.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature from the protein sequences \n",
    "Amino Acid Composition refers to frequency of each amino acid within a protein sequence. E.g. if a protein has a sequence 'MSAARQTTRKAE' it's amino acid composition can be represented as a vector of length 20:\n",
    "\n",
    "'A':3,'C':0,'D':0,'E':1,'F':0,'G':0,'H':0,'I':0,'K':1,'L':0,'M':1,'N':0,'P':0,'Q':1,'R':1,'S':1,'T':2,'V':0,'W':0,'Y':0\n",
    "\n",
    "In this way all the protein sequences can be represented as feature vector of contant length. Note that protein sequences within the same class can have different number of amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "positive_dict = SeqIO.to_dict(SeqIO.parse(\"positive-aars.txt\", \"fasta\")) ##fasta is a type of sequence format\n",
    "negative_dict = SeqIO.to_dict(SeqIO.parse(\"negative-aars.txt\", \"fasta\"))\n",
    "\n",
    "## Amino acid composition calculation##\n",
    "#c1 = ProteinAnalysis(\"AAAASTRRRTRRAWEQWERQW\").count_amino_acids()\n",
    "df1 = pd.DataFrame()\n",
    "for keys,values in positive_dict.iteritems():\n",
    "    df1 = df1.append(pd.Series(ProteinAnalysis(str(values.seq)).get_amino_acids_percent(),name='1'))\n",
    "for keys,values in negative_dict.iteritems():\n",
    "    df1 = df1.append(pd.Series(ProteinAnalysis(str(values.seq)).get_amino_acids_percent(),name='-1'))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "df1['index1'] = [int(x) for x in df1.index.values]\n",
    "#sns.pairplot(df1, hue='index1', palette=\"husl\", size=1.5); ##Slow\n",
    "sns.heatmap(df1.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# Split-out validation dataset\\n\",\n",
    "labels = df1.index.values\n",
    "df1_matrix = df1.iloc[:,range(20)].as_matrix().astype(np.float)\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(df1_matrix, labels, test_size=validation_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the hyperparameters for the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVC().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Build SVM model with different set of hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "clf_poly = SVC(kernel='poly', degree=3)\n",
    "clf_rbf = SVC(kernel='rbf', C=10)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "cv_SVM_poly_results = model_selection.cross_val_score(clf_poly, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "cv_SVM_rbf_results = model_selection.cross_val_score(clf_rbf, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print (cv_SVM_poly_results.mean(), cv_SVM_rbf_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Find a set of hyperparameters for SVM model that can give accuracy of greater than fifty percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Solution\n",
    "model1 = SVC() #add hyperparameters\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "cv_model1 = model_selection.cross_val_score(model1, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print (cv_model1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read documentaion to select the right combination of hyperparameters associated with a particular model. \n",
    "Choice of some hyperparameters could affect the interpretation of other hyperparameters for a given model. E.g. in case of SVM model the `degree` parameter is applicable only if the kernel is `poly`. The value for `degree` is ignored for all other kernels. Similarly `gamma` is not applicable is case of `linear` kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000, 10000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000, 10000]},\n",
    "                    {'kernel':['poly'], 'C': [1, 10, 100, 1000, 10000],\n",
    "                     'degree': range(10)}]\n",
    "clf_grid = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='accuracy')\n",
    "clf_grid.fit(df1_matrix,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf_grid.best_params_)\n",
    "clf_grid.cv_results_;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a SVM model using above hyperparameters and check the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_linear = SVC(kernel='linear',C=1000)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "cv_SVM_results = model_selection.cross_val_score(clf_linear, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print (cv_SVM_results.mean(),cv_results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "clf_linear = SVC(kernel='linear',C=1000)\n",
    "\n",
    "labels = df1.index.values\n",
    "df1_matrix = df1.iloc[:,range(20)].as_matrix().astype(np.float)\n",
    "print(df1_matrix.shape)\n",
    "## Fit model to the data ##\n",
    "clf_linear.fit(df1_matrix,labels)\n",
    "print(Counter(labels))\n",
    "\n",
    "## Predict labels for the original data ##\n",
    "clf_linear_predict = clf_linear.predict(df1_matrix)\n",
    "Counter(clf_linear_predict)\n",
    "#print(clf_linear_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib as plt\n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(labels,clf_linear_predict)\n",
    "print(cm)\n",
    "\n",
    "## Plot ##\n",
    "sns.heatmap(cm, square=True, annot=True, cbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract another feature - Di-Peptide Composition (DPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sequence calculate the frequency of pairwaise occurrence of amino acids. The length of the feature vector for each sequence would be 400 (20 x 20). Construct a classification model using DPC as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "aa_list = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create a series of dipeptides\n",
    "dpc_series = pd.Series(name='1')\n",
    "for x in itertools.product(aa_list,aa_list):\n",
    "    dpc_series[''.join([''.join(x)])] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate dipeptide composition for the positive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dpc = pd.DataFrame([])\n",
    "for keys,values in positive_dict.iteritems():\n",
    "    dpc_series_copy = dpc_series.copy()\n",
    "#    print (values.seq)\n",
    "    dpc_seq = [str(values.seq[i:i+2]) for i in range(len(values.seq))]\n",
    "    del dpc_seq[-1]\n",
    "    for x in dpc_seq:\n",
    "        dpc_series_copy[x] += 1\n",
    "    df_dpc = df_dpc.append(dpc_series_copy)\n",
    "#dpc_series_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly, calculate the dipeptide composition for the negative dataset and append to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for keys,values in negative_dict.iteritems():\n",
    "    dpc_series_copy = dpc_series.copy()\n",
    "    dpc_series_copy.name = '-1'\n",
    "    dpc_seq = [str(values.seq[i:i+2]) for i in range(len(values.seq))]\n",
    "    del dpc_seq[-1]\n",
    "    for x in dpc_seq:\n",
    "        dpc_series_copy[x] += 1\n",
    "    df_dpc = df_dpc.append(dpc_series_copy)\n",
    "df_dpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df_dpc.index.values\n",
    "df_dpc_matrix = df_dpc.iloc[:,range(20)].as_matrix().astype(np.float)\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(df_dpc_matrix, labels, test_size=validation_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_linear = SVC(kernel='linear',C=1000)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "cv_SVM_results = model_selection.cross_val_score(clf_linear, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print (cv_SVM_results.mean(),cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
